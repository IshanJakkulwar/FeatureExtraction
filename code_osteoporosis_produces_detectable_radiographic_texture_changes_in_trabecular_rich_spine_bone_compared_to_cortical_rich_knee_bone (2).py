# -*- coding: utf-8 -*-
"""CODE-Osteoporosis Produces Detectable Radiographic Texture Changes in Trabecular-Rich Spine Bone Compared to Cortical-Rich Knee Bone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zk3Mh9CTb4mnHwSyUgXyUk9HJp68zfI4

##Setup
"""

import sys
import importlib
import subprocess
from packaging import version

MIN_TORCH = "1.12.0"
MIN_TORCHVISION = "0.13.0"

def install_packages(cuda_index_url=None):
    """
    Installs/updates torch, torchvision, torchaudio.
    If cuda_index_url is provided, pip will use that index (useful to get CUDA-enabled wheels).
    """
    pip_cmd = [sys.executable, "-m", "pip", "install", "-U", "torch", "torchvision", "torchaudio"]
    if cuda_index_url:
        pip_cmd += ["--index-url", cuda_index_url]
    print("[INFO] Running:", " ".join(pip_cmd))
    subprocess.check_call(pip_cmd)
    importlib.invalidate_caches()

def ensure_torch():
    try:
        import torch, torchvision
        tver = torch.__version__
        tvver = torchvision.__version__
        print(f"[INFO] Found torch {tver}, torchvision {tvver}")
        if version.parse(tver) < version.parse(MIN_TORCH) or version.parse(tvver) < version.parse(MIN_TORCHVISION):
            print(f"[INFO] torch/torchvision older than required ({MIN_TORCH}/{MIN_TORCHVISION}). Upgrading now...")
            # OPTIONAL: change cuda_index_url to match your CUDA (eg. cu118 or cu117) if desired
            # e.g. cuda_index_url = "https://download.pytorch.org/whl/cu118"
            install_packages(cuda_index_url=None)
            importlib.reload(torch)
            importlib.reload(torchvision)
            print(f"[INFO] After upgrade: torch {torch.__version__}, torchvision {torchvision.__version__}")
        else:
            print("[INFO] torch/torchvision meet requirements.")
    except Exception as e:
        print("[WARN] Could not import torch/torchvision or version check failed:", e)
        print("[INFO] Installing/Upgrading torch, torchvision, torchaudio now...")
        install_packages(cuda_index_url=None)
        import torch, torchvision
        print(f"[INFO] After install: torch {torch.__version__}, torchvision {torchvision.__version__}")

ensure_torch()


print("\n[NOTE] If this cell performed an installation or upgrade, please RESTART the runtime (Runtime -> Restart runtime) before running subsequent cells.")

# Regular imports for feature extraction workflow
import matplotlib.pyplot as plt
import torch
import torchvision

from torch import nn
from torchvision import transforms

# torchinfo
try:
    from torchinfo import summary
except ImportError:
    print("[INFO] Couldn't find torchinfo... installing it.")
    !pip install -q torchinfo
    from torchinfo import summary

try:
    from going_modular.going_modular import data_setup
except ImportError:
    print("[INFO] Couldn't find going_modular scripts... downloading them from GitHub.")
    !git clone https://github.com/mrdbourke/pytorch-deep-learning
    !mv pytorch-deep-learning/going_modular .
    !rm -rf pytorch-deep-learning
    from going_modular.going_modular import data_setup

# Setup device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"
device

from google.colab import drive
drive.mount('/content/drive')

from pathlib import Path

# Base project path in Google Drive
data_path = Path("/content/drive/MyDrive/ISEF_JSHS/")
image_path = data_path / "Dataset"

# Define dataset subfolders (adjust if your dataset is organized differently)
train_dir = image_path / "Train"
test_dir = image_path / "Test"

print("Train directory:", train_dir)
print("Test directory:", test_dir)

# Transforms for EfficientNet-B0
from torchvision import models

# Use the official EfficientNet-B0 pretrained weights to get correct transforms
weights = models.EfficientNet_B0_Weights.DEFAULT
data_transforms = weights.transforms()

# Now data_transforms will handle resizing, cropping, normalization automatically
print(data_transforms)

from torchvision import datasets

# Load datasets with EfficientNet transforms
train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms)
test_dataset  = datasets.ImageFolder(test_dir,  transform=data_transforms)

print("Train classes:", train_dataset.classes)
print("Test classes:", test_dataset.classes)

# Load pretrained EfficientNet-B0
from torchvision import models

weights = models.EfficientNet_B0_Weights.DEFAULT
model = models.efficientnet_b0(weights=weights).to(device)
model.eval()  # VERY IMPORTANT â€” evaluation mode (no dropout/batchnorm updates)

print("[INFO] Loaded EfficientNet-B0 in eval mode for feature extraction")

# Print model summary
summary(model=model,
        input_size=(32, 3, 224, 224),
        col_names=["input_size", "output_size", "num_params", "trainable"],
        col_width=20,
        row_settings=["var_names"]
)

# Freeze EfficientNet weights for feature extraction
for param in model.parameters():
    param.requires_grad = False

import numpy as np

def extract_features_with_paths(model, dataset, device):
    model.eval()
    all_features, all_labels, all_sites, all_paths = [], [], [], []
    loader = DataLoader(dataset, batch_size=32, shuffle=False)

    with torch.no_grad():
        for inputs, labels in loader:
            inputs = inputs.to(device)
            feats = model.features(inputs)
            pooled = model.avgpool(feats)
            flat = torch.flatten(pooled, 1)
            all_features.append(flat.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

        # record file paths for site detection
        paths = [p for p, _ in dataset.samples]

    # Stack features
    features = np.vstack(all_features)
    labels = np.concatenate(all_labels)

    # Map folder-based labels to condition + site
    conditions, sites = [], []
    for path in paths:
        path_lower = path.lower()
        if "normal" in path_lower:
            conditions.append(0)  # Normal
        elif "osteo" in path_lower:
            conditions.append(1)  # Osteoporotic
        else:
            conditions.append(-1)

        if "knee" in path_lower:
            sites.append("knee")
        elif "spine" in path_lower:
            sites.append("spine")
        else:
            sites.append("unknown")

    return features, np.array(conditions), np.array(sites), paths

# Extract from TRAIN and TEST
train_features, train_conditions, train_sites, train_paths = extract_features_with_paths(model, train_dataset, device)
test_features, test_conditions, test_sites, test_paths     = extract_features_with_paths(model, test_dataset,  device)

# Merge train+test
features   = np.vstack([train_features, test_features])
conditions = np.concatenate([train_conditions, test_conditions])
sites      = np.concatenate([train_sites, test_sites])
file_paths = train_paths + test_paths

print("Total samples:", len(file_paths))
print("Unique sites:", set(sites))
print("Conditions check (0=Normal,1=Osteo):", np.unique(conditions, return_counts=True))

from sklearn.decomposition import PCA
from scipy.stats import ttest_ind

for site in ["spine", "knee"]:
    mask = (sites == site)
    if mask.sum() == 0:
        continue

    X_site = features[mask]
    y_site = conditions[mask]  #  Normal vs Osteo

    pca = PCA(n_components=2)
    Xp = pca.fit_transform(X_site)

    group0 = Xp[y_site == 0, 0]  # Normal
    group1 = Xp[y_site == 1, 0]  # Osteo

    print(f"\nSite: {site.capitalize()} | N={len(y_site)}")
    print(f"  Samples Normal={len(group0)}, Osteo={len(group1)}")

    if len(group0) == 0 or len(group1) == 0:
        print("  Skipping t-test (missing one group)")
        continue

    t_stat, p_val = ttest_ind(group1, group0, equal_var=False)

    print(f"  PC1 mean (Normal): {group0.mean():.3f}, PC1 mean (Osteo): {group1.mean():.3f}")
    print(f"  T-test: t={t_stat:.3f}, p={p_val:.5f}")

    plt.figure(figsize=(6,5))
    plt.scatter(Xp[y_site==0,0], Xp[y_site==0,1], alpha=0.5, label="Normal", c="blue")
    plt.scatter(Xp[y_site==1,0], Xp[y_site==1,1], alpha=0.5, label="Osteoporosis", c="red")
    plt.xlabel("PC1"); plt.ylabel("PC2")
    plt.title(f"PCA of {site.capitalize()} Radiographs")
    plt.legend()
    plt.savefig(f"/content/drive/MyDrive/ISEF_JSHS/pca_{site}.png", dpi=200)
    plt.show()